{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priority Queue implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PriorityQ:\n",
    "    def __init__(self,ty,ar=[]):\n",
    "        self.a=[]\n",
    "        self.t=ty\n",
    "        if ar:\n",
    "            for i in ar:\n",
    "                self.insert(i)\n",
    "            \n",
    "    def insert(self,item):\n",
    "        assert type(item)==self.t\n",
    "        self.a.append(item)\n",
    "        self.BuildMaxHeap()\n",
    "    \n",
    "    def heapify(self,i):\n",
    "        l=(2*i)+1\n",
    "        r=(2*i)+2\n",
    "        if(l<len(self.a) and r<len(self.a)):\n",
    "            if(self.a[l].p>self.a[i].p and self.a[l].p>self.a[r].p):\n",
    "                self.a[l],self.a[i]=self.a[i],self.a[l]\n",
    "                self.heapify(l)\n",
    "            if(self.a[r].p>self.a[i].p and self.a[r].p>self.a[l].p):\n",
    "                self.a[r],self.a[i]=self.a[i],self.a[r]\n",
    "                self.heapify(r)\n",
    "        if(l<len(self.a)):\n",
    "            if(self.a[l].p>self.a[i].p):\n",
    "                self.a[l],self.a[i]=self.a[i],self.a[l]\n",
    "                self.heapify(l)\n",
    "\n",
    "    def BuildMaxHeap(self):\n",
    "        for i in range((len(self.a)//2)-1,-1,-1):\n",
    "            self.heapify(i)\n",
    "    \n",
    "    def ExtractMax(self):\n",
    "        ans=self.a[0]\n",
    "        last=len(self.a)-1\n",
    "        self.a[0],self.a[last]=self.a[last],self.a[0]\n",
    "        self.a.pop()\n",
    "        self.heapify(0)\n",
    "        return ans\n",
    "    \n",
    "    def Max(self):\n",
    "        return self.a[0]\n",
    "    \n",
    "    def Empty(self):\n",
    "        return len(self.a)==0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chain class creates an object for a partial chain and associates it with a priority.\n",
    "Example:{[\"Lion\",\"Earth\"],50} are data members value of a chain object. Here [\"Lion\",\"Earth\"] has priority=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class chain:\n",
    "    def __init__(self):\n",
    "        self.a=[]\n",
    "        self.p=0\n",
    "    def addtochain(self,v,pri):\n",
    "        self.a.append(v)\n",
    "        self.p=pri\n",
    "    def copy(self,fr,new,pri):\n",
    "        for i in fr.a:\n",
    "            self.a.append(i)\n",
    "        self.a.append(new)\n",
    "        self.p=pri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "links store all urls of a wiki page. HTMLParser parses the webpage and stores hyperlinks in links[] list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == \"a\":\n",
    "           for name, url in attrs:\n",
    "               if name == \"href\":\n",
    "                   url = str(url)\n",
    "                   if (\"#\" not in url) and (\":\" not in url):\n",
    "                        val = url.split(\"/\")\n",
    "                        if(\"wiki\" in val):\n",
    "                            if val[-1] and (val[-1] not in links) and (val[-1]!= \"Main_Page\") and (val[-1]!=\"Terms_of_Use\") and (val[-1]!= \"Privacy_policy\"):\n",
    "                                a=val[-1].lower()\n",
    "                                links.append(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikilinks calls HTMLParser for a given name of Wiki page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WikiLinks(name):\n",
    "    parser = MyHTMLParser()\n",
    "    myurl = \"https://en.wikipedia.org/wiki/\"+name\n",
    "    response = urllib.request.urlopen(myurl)\n",
    "    html = str(response.read())\n",
    "    del links[:]\n",
    "    parser.feed(html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count function counts the identical links between start page and target page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count(start,target):\n",
    "    count=0\n",
    "    WikiLinks(start)\n",
    "    one=[]\n",
    "    for i in links:\n",
    "        one.append(i)\n",
    "    WikiLinks(target)\n",
    "    two=[]\n",
    "    for i in links:\n",
    "        two.append(i)\n",
    "    for i in one:\n",
    "        if i in two:\n",
    "            count=count+1\n",
    "    #print(count)\n",
    "    return count   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findanswer function recursively calls itself untill it finds target page\n",
    "\n",
    "It extracts the highest priority partial chain from priority queue, \n",
    "finds the last wiki page in the partial chain, \n",
    "then finds all the links in it, \n",
    "then adds each link as a partial chain to same priority queue with a priority(equal to count(eachlink,target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lion', 'earth', 'moon']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def findanswer(p,target):\n",
    "    m=p.ExtractMax()\n",
    "    #print(m.a)\n",
    "    try:\n",
    "        WikiLinks(m.a[-1])\n",
    "        if target in links:\n",
    "            m.a.append(target)\n",
    "            return m.a\n",
    "        for i in links:\n",
    "            #print(i)\n",
    "            ob=chain()\n",
    "            c=count(i,target)\n",
    "            ob.copy(m,i,c)\n",
    "            p.insert(ob)\n",
    "    except:\n",
    "        pass\n",
    "    return findanswer(p,target)\n",
    "\n",
    "def WikiChain(start,target):\n",
    "    start=start.lower()\n",
    "    target=target.lower()\n",
    "    if start ==target:\n",
    "        return \"same values\"\n",
    "    o=chain()\n",
    "    c=count(start,target)\n",
    "    o.addtochain(start,c)\n",
    "    p=PriorityQ(chain,[o])\n",
    "    return findanswer(p,target)\n",
    "\n",
    "\n",
    "answer=WikiChain(\"Lion\",\"Moon\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
